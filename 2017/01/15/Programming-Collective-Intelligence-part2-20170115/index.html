
 <!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
  
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400">
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Inconsolata:400">
    <title>机器学习（二）数据聚类 | FlamePeak</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="FlamePeak">
    

    
    <meta name="description" content="数据聚类(Data Clustering)是一种用以寻找紧密相关的事、人或观点，并将其可视化的方法。 聚类时常被用于数据量很大（data-intensive）的应用中。跟踪消费者购买行为的零售商们，除了利用常规的消费者投机信息外，还可以利用这些信息自动检测出具有相似购买模式的消费者群体，并开发出相应的零售或市场策略。 聚类在计量生物学领域也有大量的运用，可以用来寻找具有相似行为的基因组。 监督">
<meta name="keywords" content="笔记,Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习（二）数据聚类">
<meta property="og:url" content="http://flamepeak.com/2017/01/15/Programming-Collective-Intelligence-part2-20170115/index.html">
<meta property="og:site_name" content="FlamePeak">
<meta property="og:description" content="数据聚类(Data Clustering)是一种用以寻找紧密相关的事、人或观点，并将其可视化的方法。 聚类时常被用于数据量很大（data-intensive）的应用中。跟踪消费者购买行为的零售商们，除了利用常规的消费者投机信息外，还可以利用这些信息自动检测出具有相似购买模式的消费者群体，并开发出相应的零售或市场策略。 聚类在计量生物学领域也有大量的运用，可以用来寻找具有相似行为的基因组。 监督">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://flamepeak.com/sourcepictures/2017/01/15/clustering.png">
<meta property="og:image" content="http://flamepeak.com/sourcepictures/2017/01/15/cluster_dendrogram.png">
<meta property="og:image" content="http://flamepeak.com/sourcepictures/2017/01/15/printcluster.png">
<meta property="og:image" content="http://flamepeak.com/sourcepictures/2017/01/15/k_means_clustering.png">
<meta property="og:updated_time" content="2017-02-06T13:09:06.593Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习（二）数据聚类">
<meta name="twitter:description" content="数据聚类(Data Clustering)是一种用以寻找紧密相关的事、人或观点，并将其可视化的方法。 聚类时常被用于数据量很大（data-intensive）的应用中。跟踪消费者购买行为的零售商们，除了利用常规的消费者投机信息外，还可以利用这些信息自动检测出具有相似购买模式的消费者群体，并开发出相应的零售或市场策略。 聚类在计量生物学领域也有大量的运用，可以用来寻找具有相似行为的基因组。 监督">
<meta name="twitter:image" content="http://flamepeak.com/sourcepictures/2017/01/15/clustering.png">

    
    <link rel="alternative" href="/atom.xml" title="FlamePeak" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
  <meta name="google-site-verification" content="rYNq4pSdFJQ3Ir4VuV4A6TqVEEUP8o-rrwmST28FhQY">
  <meta name="baidu-site-verification" content="AL6EYSh1WZ">
</head>
</html>
  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="FlamePeak">FlamePeak</a></h1>
				<h2 class="blog-motto">We know something, but we do not know more.</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/notes">Notes</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:flamepeak.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/01/15/Programming-Collective-Intelligence-part2-20170115/" title="机器学习（二）数据聚类" itemprop="url">机器学习（二）数据聚类</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="FlamePeak" target="_blank" itemprop="author">FlamePeak</a>
		
  <p class="article-time">
    <time datetime="2017-01-15T13:24:49.000Z" itemprop="datePublished"> Published 2017-01-15</time>
    
  </p>
</header>
	<div class="article-content">
		
		<p>数据聚类(Data Clustering)是一种用以寻找紧密相关的事、人或观点，并将其可视化的方法。</p>
<p>聚类时常被用于数据量很大（data-intensive）的应用中。跟踪消费者购买行为的零售商们，除了利用常规的消费者投机信息外，还可以利用这些信息自动检测出具有相似购买模式的消费者群体，并开发出相应的零售或市场策略。 聚类在计量生物学领域也有大量的运用，可以用来寻找具有相似行为的基因组。</p>
<h2 id="监督学习与无监督学习-supervised-and-unsupervised-learning">监督学习与无监督学习 Supervised and Unsupervised Learning</h2>
<p>利用样本输入和期望输出来学习如何预测的技术被称为<strong>监督学习</strong>(Supervised Learning Methods)。其中包括：神经网络、决策树、向量支持机，以及贝叶斯过滤。采用这些方法的应用程序，会通过检查一组输入和期望的输出来进行“学习”。</p>
<p>聚类是<strong>无监督学习</strong>（Unsupervised Learning）的一个例子。与神经网络或决策树不同，无监督学习算法不是利用带有正确答案的样本数据进行“训练”。它们的目的是要在一组数据中找<strong>寻某种结构</strong>，而这些数据本身并不是我们要找的答案。<strong>聚类算法的目标是采集数据，然后从中找出不同的群组。</strong> 其它无监督学习的例子还包括<strong>非负矩阵因式分解</strong>(non-negative matrix factorization)和<strong>自组织映射</strong>(self-organizing maps)。</p>
<h2 id="聚类">聚类</h2>
<h3 id="分级聚类-hierarchical-clustering">分级聚类 Hierarchical Clustering</h3>
<p>分级聚类通过连续不断地将最为相似的群组两两合并，来构造出一个群组的层级结构。其中的每个群组都是从单一元素开始的。在每次迭代过程中，分级聚类算法会计算每两个群组间的距离，并将距离最近的两个群组合并成一个新的群组。这一过程会一直重复下去，直到只剩下一个群组为止。</p>
<figure>
<img src="/sourcepictures/2017/01/15/clustering.png" alt><figcaption>clustering.png</figcaption>
</figure>
<p>在上图中，元素的相似程度是通过它们的相对位置来体现的——两个元素距离越近，它们就越相似。开始时，群组内还只有一个元素。在第二布中，我们看到A和B，这两个紧靠在一起的元素，已经合并成一个新的群组，新群组所在的位置位于这两个元素的中间。第三步中，新群组又与C进行了合并。因为D和E现在是距离最近的两个元素，所以它们共同组成了一个新的群组。最后一步将两个群组合并到一起。</p>
<p>通常，待分级聚类完成以后，我们可以采用一种图形化的方式来展现所得的结果，这种图被称为<strong>树状图</strong>（dendrogram），图中显示了按层级排列的节点。</p>
<p><img src="/sourcepictures/2017/01/15/cluster_dendrogram.png" alt="cluster_dendrogram.png"> 树状图是分级聚类的一种可视化形式</p>
<p>树状图不仅可以利用连线来表达每个聚类的构成情况，而且还可以利用距离来体现构成聚类各元素间相隔的远近。这种图形绘制方式能够帮助我们有效的确定一个聚类中各元素间的相似程度，并以此来指示聚类的紧密程度。</p>
<p>加载数据文件： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readfile</span><span class="params">(filename)</span>:</span></span><br><span class="line">    lines = [line <span class="keyword">for</span> line <span class="keyword">in</span> open(filename)]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#第一行是列标题</span></span><br><span class="line">    colnames = line[<span class="number">0</span>].strip().split(<span class="string">'\t'</span>)[<span class="number">1</span>:]</span><br><span class="line">    rownames = []</span><br><span class="line">    data = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines[<span class="number">1</span>:]:</span><br><span class="line">        p = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="comment">#每行的第一列是行名</span></span><br><span class="line">        rownames.append(p[<span class="number">0</span>])</span><br><span class="line">        <span class="comment">#剩下部分就是该行对应的数据</span></span><br><span class="line">        data.append([float(x) <span class="keyword">for</span> x <span class="keyword">in</span> p[<span class="number">1</span>:]])</span><br><span class="line">    <span class="keyword">return</span> rownames, colnames, data</span><br></pre></td></tr></table></figure></p>
<p>使用皮尔逊相关度定义<strong>紧密度</strong>（closeness），此处皮尔逊相关度的计算代码将接受两个数字列表作为参数，并返回这两个列表的相关度分值。 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pearson</span><span class="params">(v1, v2)</span>:</span></span><br><span class="line">    <span class="comment">#简单求和</span></span><br><span class="line">    sum1 = sum(v1)</span><br><span class="line">    sum2 = sum(v2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#求平方和</span></span><br><span class="line">    sum1Sq = sum([pow(v, <span class="number">2</span>) <span class="keyword">for</span> v <span class="keyword">in</span> v1])</span><br><span class="line">    sum2Sq = sum([pow(v, <span class="number">2</span>) <span class="keyword">for</span> v <span class="keyword">in</span> v2])</span><br><span class="line"></span><br><span class="line">    <span class="comment">#求乘积之和</span></span><br><span class="line">    pSum = sum([v1[i]*v2[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(v1))])</span><br><span class="line"></span><br><span class="line">    <span class="comment">#计算r (Pearson score)</span></span><br><span class="line">    num = pSum - sum1*sum2/len(v1)</span><br><span class="line">    den = sqrt((sum1Sq-pow(sum1, <span class="number">2</span>)/len(v1))*(sum2Sq-pow(sum2, <span class="number">2</span>)/len(v1)))</span><br><span class="line">    <span class="keyword">if</span> den == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>-num/den</span><br></pre></td></tr></table></figure></p>
<p>皮尔逊相关度的计算结果在两者完全匹配的情况下为1.0, 而在两者毫无关系的情况下为0.0。上面代码的最后一行，返回的是1.0减去皮尔逊相关度之后的结果，这样的目的是为了让相似度大的两个元素之间的距离变的更小。</p>
<p>分级聚类算法中的每一个聚类，可以是树中的枝节点，也可以是与数据集中实际数据行相对应的叶节点。每一个聚类还包含指示其位置的信息，这一信息可以是来自叶节点的行数据，也可以是来自枝节点的经合并后的数据。我们可以新建一个bicluster类，将所有这些属性存放其中，并以此来描述这棵层级树。 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">bicluster</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vec, left=None, right=None, distance=<span class="number">0.0</span>, id=None)</span>:</span></span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line">        self.vec = vec</span><br><span class="line">        self.id = id</span><br><span class="line">        self.distance = distance</span><br></pre></td></tr></table></figure></p>
<p>分级聚类算法以一组对应于原始数据项的聚类开始。函数的主循环部分会尝试每一组可能的配对并计算它们的相似度，以此来找出最佳配对。最佳配对的两个聚类会被合并成一个新的聚类。新生成的聚类中所包含的数据，等于将两个旧聚类的数据求平均值后得到的结果。这一过程会一直重复下去，直到只剩下一个聚类为止。 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hcluster</span><span class="params">(rows, distance=pearson)</span>:</span></span><br><span class="line">    distances = &#123;&#125;</span><br><span class="line">    currentclustid = <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#最开始的聚类就是数据集中的行</span></span><br><span class="line">    clust = [bicluster(rows[i], id=i) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(rows))]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> len(clust)&gt;<span class="number">1</span>:</span><br><span class="line">        lowestpair = (<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">        closest = distance(clust[<span class="number">0</span>].vec, clust[<span class="number">1</span>].vec)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#遍历每一个配对，寻找最小距离</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(clust)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, len(clust)):</span><br><span class="line">                <span class="comment">#用distances来缓存距离的计算值</span></span><br><span class="line">                <span class="keyword">if</span> (clust[i].id, clust[j].id) <span class="keyword">not</span> <span class="keyword">in</span> distances:</span><br><span class="line">                    distances[(clust[i].id, clust[j].id)] = distance(clust[i].vec, clust[j].vec)</span><br><span class="line"></span><br><span class="line">                d = distances[(clust[i].id, clust[j].id)]</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> d &lt; closest:</span><br><span class="line">                    closest = d</span><br><span class="line">                    lowestpair = (i, j)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#计算两个聚类的平均值</span></span><br><span class="line">        mergevec = [(clust[lowestpair[<span class="number">0</span>]].vec[i] + clust[lowestpair[<span class="number">1</span>]].vec[i])/<span class="number">2.0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(len(clust[<span class="number">0</span>].vec))]</span><br><span class="line"></span><br><span class="line">        <span class="comment">#建立新的聚类</span></span><br><span class="line">        newcluster = bicluster(mergevec, left=clust[lowestpair[<span class="number">0</span>]], right=clust[lowestpair[<span class="number">1</span>]], distance=closest, id=currentclustid)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#不在原始集合中的聚类，其id为负数</span></span><br><span class="line">        currentclustid -= <span class="number">-1</span></span><br><span class="line">        <span class="keyword">del</span> clust[lowestpair[<span class="number">1</span>]]</span><br><span class="line">        <span class="keyword">del</span> clust[lowestpair[<span class="number">0</span>]]</span><br><span class="line">        clust.append(newcluster)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> clust[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></p>
<p>加载文件并调用hcluster方法： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">blognames, words, data = readfile(<span class="string">'blogdata.txt'</span>)</span><br><span class="line">clust = hcluster(data)</span><br></pre></td></tr></table></figure></p>
<p>我们可以编写一个程序，递归遍历聚类树，并将其以类似文件系统层级结构的形式打印出来： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printclust</span><span class="params">(clust, labels=None, n=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="comment">#利用缩进来建立层级布局</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">print</span> <span class="string">' '</span>,</span><br><span class="line">    <span class="keyword">if</span> clust.id &lt;<span class="number">0</span>:</span><br><span class="line">        <span class="comment">#负数表示这是一个分支</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'-'</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment">#正数表示这是一个叶节点</span></span><br><span class="line">        <span class="keyword">if</span> labels ==<span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">print</span> clust.id</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">print</span> labels[clust.id]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#现在开始打印右侧分支和左侧分支</span></span><br><span class="line">    <span class="keyword">if</span> clust.left !=<span class="keyword">None</span>:</span><br><span class="line">        printclust(clust.left, labels=labels, n=n+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> clust.right !=<span class="keyword">None</span>:</span><br><span class="line">        printclust(clust.right, labels=labels, n=n+<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>结果如图：</p>
<p><img src="/sourcepictures/2017/01/15/printcluster.png" alt="printcluster.png"> <strong>数据矩阵转置rotate</strong> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#矩阵转置rotate</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rotatematrix</span><span class="params">(data)</span>:</span></span><br><span class="line">    newdata = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data[<span class="number">0</span>])):</span><br><span class="line">        newrow=[data[j][i] <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data))]</span><br><span class="line">        newdata.append(newrow)</span><br><span class="line">    <span class="keyword">return</span> newdata</span><br></pre></td></tr></table></figure></p>
<hr>
<h3 id="k-均值聚类-k-means-clustering">K-均值聚类 K-Means Clustering</h3>
<p>分级聚类的结果为我们返回了一棵形象直观的树，但是这种方法有两个缺点。在没有额外投入的情况下，树形视图是不会真正将数据拆分成不同组的，而且该算法的计算量非常惊人。因为我们必须计算每两个配对项之间的关系，并且在合并项之后，这些关系还得重新再计算，所以在处理很大规模的数据集时，该算法的运行速度会非常缓慢。</p>
<p>除了分级聚类外，另一种可供选择的聚类方法被称为<strong>K-均值聚类</strong>。这种算法完全不同于分级聚类，因为我们会预先告诉算法希望生成的聚类数量，然后算法会根据数据的结构状况来确定聚类的大小。</p>
<p>K-均值聚类算法首先会随机确定<code>k</code>个中心位置（位于空间中代表聚类中心的点），然后将各个数据项分配给最临近的中心点。待分配完成后，聚类中心就会移到分配给该聚类的所有节点的平均位置处，然后整个分配过程重新开始。这一过程会一直重复下去，直到分配过程不再产生变化为止。下图显示了这一过程，涉及5个数据项和2个聚类。</p>
<p><img src="/sourcepictures/2017/01/15/k_means_clustering.png" alt="k_means_clustering.png"> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kcluster</span><span class="params">(rows, distance=pearson,k=<span class="number">4</span>)</span>:</span></span><br><span class="line">    <span class="comment">#确定每个点的最小值和最大值</span></span><br><span class="line">    ranges = [(min([row[i] <span class="keyword">for</span> row <span class="keyword">in</span> rows]),max([row[i] <span class="keyword">for</span> row <span class="keyword">in</span> rows])) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(rows[<span class="number">0</span>]))]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#随机创建k个中心点</span></span><br><span class="line">    clusters = [[random.random()*(ranges[i][<span class="number">1</span>]-ranges[i][<span class="number">0</span>])+ranges[i][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(rows[<span class="number">0</span>]))] <span class="keyword">for</span> j <span class="keyword">in</span> range(k)]</span><br><span class="line"></span><br><span class="line">    lastmatches = <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'Iteration %d'</span> %t</span><br><span class="line">        bestmatches = [[] <span class="keyword">for</span> i <span class="keyword">in</span> range(k)]</span><br><span class="line"></span><br><span class="line">        <span class="comment">#在每一行中寻找距离最近的中心点</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(rows)):</span><br><span class="line">            row = rows[j]</span><br><span class="line">            bestmatch = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">                d = distance(clusters[i], row)</span><br><span class="line">                <span class="keyword">if</span> d &lt;distance(clusters[bestmatch], row):</span><br><span class="line">                    bestmatch = i</span><br><span class="line">            bestmatches[bestmatch].append(j)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#如果结果与上次相同，则整个过程结束</span></span><br><span class="line">        <span class="keyword">if</span> bestmatches == lastmatches:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        lastmatches = bestmatches</span><br><span class="line"></span><br><span class="line">        <span class="comment">#把中心点移到其所有成员的平均位置处</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">            avgs = [<span class="number">0.0</span>]*len(rows[<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">if</span> len(bestmatches[i])&gt;<span class="number">0</span>:</span><br><span class="line">                <span class="keyword">for</span> rowid <span class="keyword">in</span> bestmatches[i]:</span><br><span class="line">                    <span class="keyword">for</span> m <span class="keyword">in</span> range(len(rows[rowid])):</span><br><span class="line">                        avgs[m] += rows[rowid][m]</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(len(avgs)):</span><br><span class="line">                    avgs[j] /= len(bestmatches[i])</span><br><span class="line">                clusters[i] = avgs</span><br><span class="line">    <span class="keyword">return</span> bestmatches</span><br></pre></td></tr></table></figure></p>
<p>上述代码在每个变量的值域范围内构造了一组聚类。当每次迭代进行的时候，算法会将每一行数据分配给某个中心点，然后再将中心点的数据更新为分配给它的所有项的平均位置。当分配情况与前一次相同时，迭代过程就结束了，同时算法会返回<code>k</code>组序列，其中每个序列代表一个聚类。与分级聚类相比，该算法为产生最终结果所须迭代的次数是非常少的。</p>
<p>由于函数选用的中心点作为开始，所以返回结果的顺序几乎总是不同的。根据中心点的初始位置的不同，最终聚类中所包含的内容也可能会有所不同。</p>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/人工智能/">人工智能</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/笔记/">笔记</a><a href="/tags/Machine-Learning/">Machine Learning</a>
  </div>

</div>


	<div class="article-share" id="share">
	
	  <div data-url="http://flamepeak.com/2017/01/15/Programming-Collective-Intelligence-part2-20170115/" data-title="机器学习（二）数据聚类 | FlamePeak" data-tsina="null" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2017/01/16/Python-feedparser-usage-20170116/" title="Python feedparser 网页无法打开问题解决">
  <strong>上一篇：</strong><br/>
  <span>
  Python feedparser 网页无法打开问题解决</span>
</a>
</div>


<div class="next">
<a href="/2017/01/13/Programming-Collective-Intelligence-part1-20170113/"  title="机器学习（一）推荐">
 <strong>下一篇：</strong><br/> 
 <span>机器学习（一）推荐
</span>
</a>
</div>

</nav>

	

</div>  

      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
 
 <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#监督学习与无监督学习-supervised-and-unsupervised-learning"><span class="toc-number">1.</span> <span class="toc-text">监督学习与无监督学习 Supervised and Unsupervised Learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#聚类"><span class="toc-number">2.</span> <span class="toc-text">聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#分级聚类-hierarchical-clustering"><span class="toc-number">2.1.</span> <span class="toc-text">分级聚类 Hierarchical Clustering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#k-均值聚类-k-means-clustering"><span class="toc-number">2.2.</span> <span class="toc-text">K-均值聚类 K-Means Clustering</span></a></li></ol></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  


  
<div class="categorieslist">
	<p class="asidetitle">Categories</p>
		<ul>
		
		  
			<li><a href="/categories/Android/" title="Android">Android<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/Cryptography/" title="Cryptography">Cryptography<sup>16</sup></a></li>
		  
		
		  
			<li><a href="/categories/Hardware/" title="Hardware">Hardware<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/Life/" title="Life">Life<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/Linux/" title="Linux">Linux<sup>43</sup></a></li>
		  
		
		  
			<li><a href="/categories/Network-Security/" title="Network Security">Network Security<sup>19</sup></a></li>
		  
		
		  
			<li><a href="/categories/Python/" title="Python">Python<sup>42</sup></a></li>
		  
		
		  
			<li><a href="/categories/Tools/" title="Tools">Tools<sup>19</sup></a></li>
		  
		
		  
			<li><a href="/categories/Web前端/" title="Web前端">Web前端<sup>20</sup></a></li>
		  
		
		  
			<li><a href="/categories/Web后端/" title="Web后端">Web后端<sup>14</sup></a></li>
		  
		
		  
			<li><a href="/categories/人工智能/" title="人工智能">人工智能<sup>7</sup></a></li>
		  
		
		  
			<li><a href="/categories/百家杂谈/" title="百家杂谈">百家杂谈<sup>21</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/Python/" title="Python">Python<sup>43</sup></a></li>
			
		
			
				<li><a href="/tags/Linux/" title="Linux">Linux<sup>33</sup></a></li>
			
		
			
				<li><a href="/tags/C/" title="C">C<sup>21</sup></a></li>
			
		
			
				<li><a href="/tags/笔记/" title="笔记">笔记<sup>18</sup></a></li>
			
		
			
				<li><a href="/tags/cryptography/" title="cryptography">cryptography<sup>11</sup></a></li>
			
		
			
				<li><a href="/tags/Hexo/" title="Hexo">Hexo<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/JavaScript/" title="JavaScript">JavaScript<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/Life/" title="Life">Life<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/MongoDB/" title="MongoDB">MongoDB<sup>7</sup></a></li>
			
		
			
				<li><a href="/tags/Network-Security/" title="Network Security">Network Security<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/Mysql/" title="Mysql">Mysql<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/Kali/" title="Kali">Kali<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Docker/" title="Docker">Docker<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Learning/" title="Learning">Learning<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Scrapy/" title="Scrapy">Scrapy<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Tools/" title="Tools">Tools<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/VPN/" title="VPN">VPN<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/读书/" title="读书">读书<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/Tips/" title="Tips">Tips<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/人生/" title="人生">人生<sup>3</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="https://laod.cn/hosts/2017-google-hosts.html" target="_blank" title="Google Hosts">Google Hosts</a>
            
          </li>
        
          <li>
            
            	<a href="http://overapi.com" target="_blank" title="OverAPI">OverAPI</a>
            
          </li>
        
          <li>
            
            	<a href="https://devdocs.io" target="_blank" title="DevDocs">DevDocs</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>

    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> 善良   善学   勇敢   坚毅 <br/>
			努力   克制   谦虚   执着</p>
	</section>
	 
	<div id="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">Hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2021 
		
		<a href="/about" target="_blank" title="FlamePeak">FlamePeak</a>
		
		





		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
        getSize();
        if (myWidth >= 1024) {
          $('#toc.toc-aside').css('display', 'block');
          c.click();
        }
  
  $(window).resize(function(){
    getSize();
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
      
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});
</script>











<!-- Analytics Begin -->
<!--%- partial('analytics') %-->
<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.staticfile.org/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>

